{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c36dc59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio actual: c:\\Users\\danie\\Desktop\\MIAX - BME\\Bloque 2 - Finanzas\\Renta Variable\\TAREA 3\\Practica Renta Variable_DanielGarciaLopez_77856928L\\notebooks\n",
      "‚úÖ Importaci√≥n exitosa desde src.config\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Verificamos d√≥nde estamos\n",
    "current_dir = os.getcwd()\n",
    "print(f\"Directorio actual: {current_dir}\")\n",
    "\n",
    "# Intentamos a√±adir la carpeta superior al path\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Comprobaci√≥n de seguridad: Si 'src' est√° en la misma carpeta, a√±adimos la actual tambi√©n\n",
    "sys.path.append(current_dir)\n",
    "\n",
    "try:\n",
    "    from src.config import INVALID_PRICES, VALID_STATUS_CODES, VENUES\n",
    "    print(\"‚úÖ Importaci√≥n exitosa desde src.config\")\n",
    "except ModuleNotFoundError:\n",
    "    print(\"‚ùå Fallo\")\n",
    "\n",
    "DATA_PATH = r\"../data/DATA_BIG\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb871d5",
   "metadata": {},
   "source": [
    "### Ingesta, Limpieza y Sincronizaci√≥n de Microestructura\n",
    "\n",
    "En este bloque se implementa la l√≥gica cr√≠tica para procesar los datos crudos del proveedor. Se definen dos funciones encargadas de transformar los archivos CSV en informaci√≥n operativa fiable:\n",
    "\n",
    "* **`load_and_clean_venue_data`**: Procesa un mercado individual aplicando tres filtros de calidad basados en las especificaciones del proveedor:\n",
    "    * **Filtrado de \"Magic Numbers\":** Elimina precios sint√©ticos (como `999,999.999`) que representan √≥rdenes de mercado o estados no operables.\n",
    "    * **Sincronizaci√≥n de Estados (STS):** Utiliza `pd.merge_asof` (con direcci√≥n *backward*) para cruzar as√≠ncronamente las cotizaciones (QTE) con los estados del mercado (STS). Esto permite asignar a cada tick su estado de mercado vigente exacto.\n",
    "    * **Filtro de \"Continuous Trading\":** Descarta cualquier cotizaci√≥n que ocurra durante subastas, paradas o cierres, manteniendo solo aquellas v√°lidas para arbitraje inmediato (seg√∫n los c√≥digos v√°lidos definidos en la documentaci√≥n).\n",
    "\n",
    "*  **`load_all_venues_for_isin`**: Funci√≥n que itera sobre todos los mercados disponibles (BME, AQUIS, CBOE, TURQUOISE), ejecuta la limpieza anterior y consolida los resultados en un √∫nico DataFrame vertical (*Long Format*) ordenado temporalmente.\n",
    "\n",
    "La estructrua del dataframe esperado tras este paso debe ser algo asi:\n",
    "| epoch (Tiempo) | venue | px_bid_0 | qty_bid_0 | px_ask_0 | qty_ask_0 | market_trading_status |\n",
    "|----------------|-------|----------|-----------|----------|-----------|------------------------|\n",
    "| 170000000001   | BME   | 10.50    | 500       | 10.52    | 200       | Open                   |\n",
    "| 170000000002   | AQUIS | 10.49    | 1000      | 10.53    | 600       | Open                   |\n",
    "| 170000000005   | BME   | 10.51    | 300       | 10.52    | 150       | Open                   |\n",
    "| 170000000008   | CBOE  | 10.50    | 2000      | 10.51    | 500       | Open                   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e4b1c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 2 (DEFINITIVA V3): CARGA INTELIGENTE (Auto-detecci√≥n de separador)\n",
    "\n",
    "# Mapping de nombres\n",
    "MIC_MAPPING = {\n",
    "    \"BME\": \"XMAD\",\n",
    "    \"AQUIS\": \"AQEU\",\n",
    "    \"CBOE\": \"CEUX\",      \n",
    "    \"TURQUOISE\": \"TQEX\"  \n",
    "}\n",
    "\n",
    "def load_and_clean_venue_data(data_path, date, isin, venue_name):\n",
    "    \"\"\"\n",
    "    Carga datos gestionando autom√°ticamente separadores (; o ,) y errores de columnas.\n",
    "    \"\"\"\n",
    "    file_mic = MIC_MAPPING.get(venue_name, venue_name)\n",
    "    \n",
    "    # Construcci√≥n de rutas (Estrategia doble: carpeta anidada o plana)\n",
    "    path_v1 = os.path.join(data_path, f\"{venue_name}_{date}\") # DATA/VENUE_DATE/\n",
    "    path_v2 = data_path                                        # DATA/\n",
    "    \n",
    "    qte_name = f\"QTE_{date}_{isin}_*_{file_mic}_*.csv.gz\"\n",
    "    sts_name = f\"STS_{date}_{isin}_*_{file_mic}_*.csv.gz\"\n",
    "    \n",
    "    # B√∫squeda de archivos\n",
    "    qte_files = glob.glob(os.path.join(path_v1, qte_name)) or glob.glob(os.path.join(path_v2, qte_name))\n",
    "    sts_files = glob.glob(os.path.join(path_v1, sts_name)) or glob.glob(os.path.join(path_v2, sts_name))\n",
    "    \n",
    "    if not qte_files or not sts_files:\n",
    "        return None\n",
    "\n",
    "    # --- LECTURA ROBUSTA (Aqu√≠ estaba el fallo) ---\n",
    "    try:\n",
    "        # Intentamos leer primero con coma (est√°ndar)\n",
    "        df_qte = pd.read_csv(qte_files[0], compression='gzip', sep=',')\n",
    "        \n",
    "        # Si leemos y solo hay 1 columna, es sospechoso -> Probamos con punto y coma\n",
    "        if len(df_qte.columns) < 2:\n",
    "            df_qte = pd.read_csv(qte_files[0], compression='gzip', sep=';')\n",
    "            \n",
    "        # Hacemos lo mismo para el STS\n",
    "        df_sts = pd.read_csv(sts_files[0], compression='gzip', sep=',')\n",
    "        if len(df_sts.columns) < 2:\n",
    "            df_sts = pd.read_csv(sts_files[0], compression='gzip', sep=';')\n",
    "            \n",
    "        # Limpieza de nombres de columnas (quita espacios extra tipo \" epoch\")\n",
    "        df_qte.columns = df_qte.columns.str.strip()\n",
    "        df_sts.columns = df_sts.columns.str.strip()\n",
    "        \n",
    "        # VERIFICACI√ìN: Si la columna clave no est√°, lanzamos error informativo\n",
    "        if 'px_bid_0' not in df_qte.columns:\n",
    "            raise ValueError(f\"Columnas encontradas: {list(df_qte.columns)}. Falta 'px_bid_0'.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è Error leyendo archivo de {venue_name}: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # --- LIMPIEZA 1: MAGIC NUMBERS ---\n",
    "    for price in INVALID_PRICES:\n",
    "        if 'px_bid_0' in df_qte.columns and 'px_ask_0' in df_qte.columns:\n",
    "            mask_invalid = np.isclose(df_qte['px_bid_0'], price) | np.isclose(df_qte['px_ask_0'], price)\n",
    "            df_qte = df_qte[~mask_invalid]\n",
    "    \n",
    "    # --- LIMPIEZA 2: MARKET STATUS ---\n",
    "    df_qte = df_qte.sort_values('epoch')\n",
    "    df_sts = df_sts.sort_values('epoch')\n",
    "    \n",
    "    df_merged = pd.merge_asof(\n",
    "        df_qte, \n",
    "        df_sts[['epoch', 'market_trading_status']], \n",
    "        on='epoch', \n",
    "        direction='backward'\n",
    "    )\n",
    "    \n",
    "    if venue_name not in VALID_STATUS_CODES:\n",
    "        valid_codes = []\n",
    "    else:\n",
    "        valid_codes = VALID_STATUS_CODES[venue_name]\n",
    "    \n",
    "    df_clean = df_merged[df_merged['market_trading_status'].isin(valid_codes)].copy()\n",
    "    df_clean['venue'] = venue_name \n",
    "    \n",
    "    cols_to_keep = ['epoch', 'venue', 'px_bid_0', 'qty_bid_0', 'px_ask_0', 'qty_ask_0', 'market_trading_status']\n",
    "    # Aseguramos que existan las columnas antes de filtrar\n",
    "    existing_cols = [c for c in cols_to_keep if c in df_clean.columns]\n",
    "    return df_clean[existing_cols]\n",
    "\n",
    "def load_all_venues_for_isin(data_path, date, isin):\n",
    "    all_data = []\n",
    "    print(f\"Iniciando carga para {isin} en {date}...\")\n",
    "    print(f\"Ruta base: {os.path.abspath(data_path)}\")\n",
    "    \n",
    "    for venue in VENUES:\n",
    "        df_venue = load_and_clean_venue_data(data_path, date, isin, venue)\n",
    "        \n",
    "        if df_venue is not None and not df_venue.empty:\n",
    "            all_data.append(df_venue)\n",
    "            print(f\"  ‚úÖ {venue}: Cargados {len(df_venue)} ticks.\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå {venue}: No se encontraron datos v√°lidos.\")\n",
    "            \n",
    "    if not all_data:\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    full_df = pd.concat(all_data, ignore_index=True)\n",
    "    full_df = full_df.sort_values('epoch')\n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd91732",
   "metadata": {},
   "source": [
    "### Validaci√≥n de Ingesta \n",
    "\n",
    "Antes de proceder a la construcci√≥n del *Consolidated Tape*, es fundamental validar que el proceso ETL (Extracci√≥n, Transformaci√≥n y Carga) funciona correctamente sobre una muestra controlada.\n",
    "\n",
    "En este bloque ejecutamos una prueba unitaria con un activo (ISIN), en este caso GRIFOLS y fecha espec√≠ficos para verificar:\n",
    "\n",
    "1.  **Integridad de los datos:** Confirmar que la funci√≥n de carga cruza correctamente los ficheros de precios (QTE) y estados (STS) sin generar errores de ejecuci√≥n.\n",
    "2.  **Fragmentaci√≥n visible:** Comprobar que, efectivamente, recuperamos datos de m√∫ltiples centros de negociaci√≥n (*Venues*) para el mismo activo, condici√≥n necesaria para que exista arbitraje.\n",
    "3.  **Volumen de datos:** Verificar que los filtros de calidad (como la eliminaci√≥n de *Magic Numbers*) no est√°n descartando la totalidad de la muestra y que obtenemos un n√∫mero razonable de ticks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "801738fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando carga para ES0171996087 en 2025-11-07...\n",
      "Ruta base: c:\\Users\\danie\\Desktop\\MIAX - BME\\Bloque 2 - Finanzas\\Renta Variable\\TAREA 3\\Practica Renta Variable_DanielGarciaLopez_77856928L\\data\\DATA_BIG\n",
      "  ‚úÖ BME: Cargados 44144 ticks.\n",
      "  ‚úÖ AQUIS: Cargados 17481 ticks.\n",
      "  ‚úÖ CBOE: Cargados 20912 ticks.\n",
      "  ‚úÖ TURQUOISE: Cargados 7435 ticks.\n",
      "\n",
      "¬°√âXITO! Datos cargados y limpios:\n",
      "                  epoch      venue  px_bid_0  qty_bid_0  px_ask_0  qty_ask_0  \\\n",
      "44144  1762502417476028      AQUIS    10.275      621.0       NaN        NaN   \n",
      "44145  1762502417476039      AQUIS    10.275      621.0    10.485      621.0   \n",
      "82537  1762502417500397  TURQUOISE    10.300        5.0       NaN        NaN   \n",
      "82538  1762502417500693  TURQUOISE    10.330      311.0       NaN        NaN   \n",
      "82539  1762502417500708  TURQUOISE    10.330      311.0    10.430      311.0   \n",
      "\n",
      "       market_trading_status  \n",
      "44144              5308427.0  \n",
      "44145              5308427.0  \n",
      "82537              7608181.0  \n",
      "82538              7608181.0  \n",
      "82539              7608181.0  \n",
      "\n",
      "Total de ticks procesados: 89972\n",
      "Venues encontrados: ['AQUIS' 'TURQUOISE' 'BME' 'CBOE']\n"
     ]
    }
   ],
   "source": [
    "# CELDA 3: PRUEBA DE CARGA\n",
    "\n",
    "# Configura aqu√≠ un caso real que tengas en tus carpetas\n",
    "TEST_DATE = \"2025-11-07\" \n",
    "TEST_ISIN = \"ES0171996087\" \n",
    "\n",
    "try:\n",
    "    df_ticks = load_all_venues_for_isin(DATA_PATH, TEST_DATE, TEST_ISIN)\n",
    "    \n",
    "    if not df_ticks.empty:\n",
    "        print(\"\\n¬°√âXITO! Datos cargados y limpios:\")\n",
    "        print(df_ticks.head())\n",
    "        print(f\"\\nTotal de ticks procesados: {len(df_ticks)}\")\n",
    "        print(\"Venues encontrados:\", df_ticks['venue'].unique())\n",
    "    else:\n",
    "        print(\"\\nNo se encontraron datos. Verifica PATH, FECHA e ISIN.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error durante la ejecuci√≥n: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119ad37c",
   "metadata": {},
   "source": [
    "### Construcci√≥n del \"Virtual Consolidated Tape\"\n",
    "\n",
    "Para detectar arbitraje, es necesario comparar los precios de todos los centros de negociaci√≥n (*Venues*) en el mismo instante exacto. Sin embargo, los datos originales llegan como eventos as√≠ncronos (una fila por cada actualizaci√≥n de un solo mercado).\n",
    "\n",
    "En este bloque transformamos los datos al formato necesario para el an√°lisis:\n",
    "\n",
    "1.  **Pivotaje (Wide Format):** Reestructuramos el DataFrame para que el √≠ndice sea el tiempo (`epoch`) y las columnas representen los precios (*Bid/Ask*) y vol√∫menes de cada mercado simult√°neamente.\n",
    "2.  **Alineaci√≥n Temporal (`Forward Fill`):** Dado que los mercados no se actualizan al un√≠sono, utilizamos la t√©cnica de `ffill`. Esto asume que el √∫ltimo precio conocido de un mercado sigue vigente hasta que llega una nueva actualizaci√≥n, simulando la visi√≥n persistente que tendr√≠a un *Smart Order Router* (SOR) en tiempo real.\n",
    "\n",
    "| Tiempo | Evento Real              | ¬øQu√© ve Pandas sin ffill?      | ¬øQu√© ve Pandas CON ffill?        |\n",
    "|--------|---------------------------|----------------------------------|-----------------------------------|\n",
    "| T=1    | BME cambia a 10‚Ç¨          | BME=10, CBOE=NaN                 | BME=10, CBOE=9.98 (del pasado)    |\n",
    "| T=2    | (Nadie hace nada)         | BME=NaN, CBOE=NaN                | BME=10, CBOE=9.98                 |\n",
    "| T=3    | CBOE cambia a 9.99‚Ç¨       | BME=NaN, CBOE=9.99               | BME=10, CBOE=9.99                 |\n",
    "\n",
    "3.  **Limpieza:** Se eliminan los instantes iniciales donde no todos los mercados han cotizado a√∫n, garantizando que siempre comparamos precios completos.\n",
    "\n",
    "| Tiempo | Evento Real              | Estado del Tape (Lo que ve Python)                   | Acci√≥n de Limpieza (dropna)                   |\n",
    "|--------|---------------------------|-------------------------------------------------------|------------------------------------------------|\n",
    "| T=1    | BME abre a 10.00‚Ç¨         | BME=10.00, AQUIS=NaN, CBOE=NaN                        | üóëÔ∏è BORRAR (Faltan 2 mercados)                  |\n",
    "| T=2    | AQUIS abre a 10.01‚Ç¨       | BME=10.00, AQUIS=10.01, CBOE=NaN                      | üóëÔ∏è BORRAR (Falta CBOE)                         |\n",
    "| T=3    | (Silencio)                | BME=10.00, AQUIS=10.01, CBOE=NaN                      | üóëÔ∏è BORRAR (Sigue faltando CBOE)               |\n",
    "| T=4    | CBOE abre a 9.99‚Ç¨         | BME=10.00, AQUIS=10.01, CBOE=9.99                     | ‚úÖ MANTENER (¬°Ya est√°n todos!)                 |\n",
    "| T=5    | BME sube a 10.02‚Ç¨         | BME=10.02, AQUIS=10.01, CBOE=9.99                     | ‚úÖ MANTENER                                    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f26f060",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construyendo el Consolidated Tape...\n",
      "Dimensiones: (86744, 16)\n",
      "Primeras 5 filas (Precios alineados de todos los mercados):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AQUIS_px_ask_0</th>\n",
       "      <th>BME_px_ask_0</th>\n",
       "      <th>CBOE_px_ask_0</th>\n",
       "      <th>TURQUOISE_px_ask_0</th>\n",
       "      <th>AQUIS_px_bid_0</th>\n",
       "      <th>BME_px_bid_0</th>\n",
       "      <th>CBOE_px_bid_0</th>\n",
       "      <th>TURQUOISE_px_bid_0</th>\n",
       "      <th>AQUIS_qty_ask_0</th>\n",
       "      <th>BME_qty_ask_0</th>\n",
       "      <th>CBOE_qty_ask_0</th>\n",
       "      <th>TURQUOISE_qty_ask_0</th>\n",
       "      <th>AQUIS_qty_bid_0</th>\n",
       "      <th>BME_qty_bid_0</th>\n",
       "      <th>CBOE_qty_bid_0</th>\n",
       "      <th>TURQUOISE_qty_bid_0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1762502419492911</th>\n",
       "      <td>10.47</td>\n",
       "      <td>10.395</td>\n",
       "      <td>10.425</td>\n",
       "      <td>10.43</td>\n",
       "      <td>10.37</td>\n",
       "      <td>10.365</td>\n",
       "      <td>10.37</td>\n",
       "      <td>10.37</td>\n",
       "      <td>621.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762502419513599</th>\n",
       "      <td>10.47</td>\n",
       "      <td>10.395</td>\n",
       "      <td>10.425</td>\n",
       "      <td>10.43</td>\n",
       "      <td>10.37</td>\n",
       "      <td>10.365</td>\n",
       "      <td>10.37</td>\n",
       "      <td>10.37</td>\n",
       "      <td>621.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762502419517827</th>\n",
       "      <td>10.47</td>\n",
       "      <td>10.395</td>\n",
       "      <td>10.425</td>\n",
       "      <td>10.43</td>\n",
       "      <td>10.37</td>\n",
       "      <td>10.365</td>\n",
       "      <td>10.37</td>\n",
       "      <td>10.37</td>\n",
       "      <td>621.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762502419517828</th>\n",
       "      <td>10.47</td>\n",
       "      <td>10.395</td>\n",
       "      <td>10.425</td>\n",
       "      <td>10.43</td>\n",
       "      <td>10.37</td>\n",
       "      <td>10.365</td>\n",
       "      <td>10.37</td>\n",
       "      <td>10.37</td>\n",
       "      <td>621.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762502419517831</th>\n",
       "      <td>10.47</td>\n",
       "      <td>10.395</td>\n",
       "      <td>10.425</td>\n",
       "      <td>10.43</td>\n",
       "      <td>10.37</td>\n",
       "      <td>10.365</td>\n",
       "      <td>10.37</td>\n",
       "      <td>10.37</td>\n",
       "      <td>621.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AQUIS_px_ask_0  BME_px_ask_0  CBOE_px_ask_0  \\\n",
       "epoch                                                           \n",
       "1762502419492911           10.47        10.395         10.425   \n",
       "1762502419513599           10.47        10.395         10.425   \n",
       "1762502419517827           10.47        10.395         10.425   \n",
       "1762502419517828           10.47        10.395         10.425   \n",
       "1762502419517831           10.47        10.395         10.425   \n",
       "\n",
       "                  TURQUOISE_px_ask_0  AQUIS_px_bid_0  BME_px_bid_0  \\\n",
       "epoch                                                                \n",
       "1762502419492911               10.43           10.37        10.365   \n",
       "1762502419513599               10.43           10.37        10.365   \n",
       "1762502419517827               10.43           10.37        10.365   \n",
       "1762502419517828               10.43           10.37        10.365   \n",
       "1762502419517831               10.43           10.37        10.365   \n",
       "\n",
       "                  CBOE_px_bid_0  TURQUOISE_px_bid_0  AQUIS_qty_ask_0  \\\n",
       "epoch                                                                  \n",
       "1762502419492911          10.37               10.37            621.0   \n",
       "1762502419513599          10.37               10.37            621.0   \n",
       "1762502419517827          10.37               10.37            621.0   \n",
       "1762502419517828          10.37               10.37            621.0   \n",
       "1762502419517831          10.37               10.37            621.0   \n",
       "\n",
       "                  BME_qty_ask_0  CBOE_qty_ask_0  TURQUOISE_qty_ask_0  \\\n",
       "epoch                                                                  \n",
       "1762502419492911          422.0           205.0                311.0   \n",
       "1762502419513599          210.0           205.0                311.0   \n",
       "1762502419517827          210.0           205.0                311.0   \n",
       "1762502419517828          210.0           205.0                311.0   \n",
       "1762502419517831          210.0           205.0                311.0   \n",
       "\n",
       "                  AQUIS_qty_bid_0  BME_qty_bid_0  CBOE_qty_bid_0  \\\n",
       "epoch                                                              \n",
       "1762502419492911            286.0          346.0           116.0   \n",
       "1762502419513599            286.0          346.0           116.0   \n",
       "1762502419517827            286.0          346.0           116.0   \n",
       "1762502419517828            286.0          346.0           116.0   \n",
       "1762502419517831            286.0          346.0           116.0   \n",
       "\n",
       "                  TURQUOISE_qty_bid_0  \n",
       "epoch                                  \n",
       "1762502419492911                 46.0  \n",
       "1762502419513599                 46.0  \n",
       "1762502419517827                 46.0  \n",
       "1762502419517828                 46.0  \n",
       "1762502419517831                 46.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_consolidated_tape(df_all_venues):\n",
    "\n",
    "    if df_all_venues.empty:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # 1. Pivotar: Convertimos VENUES en COLUMNAS\n",
    "    # Usamos 'last' por si hay m√∫ltiples actualizaciones en el mismo microsegundo exacto\n",
    "    tape = df_all_venues.pivot_table(\n",
    "        index='epoch', \n",
    "        columns='venue', \n",
    "        values=['px_bid_0', 'px_ask_0', 'qty_bid_0', 'qty_ask_0'],\n",
    "        aggfunc='last' \n",
    "    )\n",
    "    \n",
    "    # 2. Alineaci√≥n temporal (ffill)\n",
    "    tape = tape.ffill()\n",
    "    \n",
    "    # 3. Limpieza \n",
    "    tape = tape.dropna()\n",
    "    \n",
    "    # 4. Aplanar nombres de columnas \n",
    "    # Ejemplo transformaci√≥n: ('px_bid_0', 'BME') -> 'BME_px_bid_0'\n",
    "    tape.columns = [f\"{col[1]}_{col[0]}\" for col in tape.columns]\n",
    "    \n",
    "    return tape\n",
    "\n",
    "# --- EJECUCI√ìN ---\n",
    "try:\n",
    "    print(\"Construyendo el Consolidated Tape...\")\n",
    "    \n",
    "    # Usamos el df_ticks que cargaste exitosamente en el paso anterior\n",
    "    consolidated_tape = build_consolidated_tape(df_ticks)\n",
    "    \n",
    "    print(f\"Dimensiones: {consolidated_tape.shape}\")\n",
    "    print(\"Primeras 5 filas (Precios alineados de todos los mercados):\")\n",
    "    display(consolidated_tape.head()) \n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error creando el tape: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d62728f",
   "metadata": {},
   "source": [
    "### 5. Motor de Detecci√≥n de Oportunidades (Signal Generation)\n",
    "\n",
    "Una vez construido el *Consolidated Tape*, procedemos a identificar instantes donde se viola la eficiencia del mercado, es decir, cuando el precio de compra en un mercado supera al precio de venta en otro.\n",
    "\n",
    "Se implementan las siguientes reglas de negocio:\n",
    "\n",
    "1.  **Best Bid/Offer Global:** Para cada *epoch*, calculamos el precio m√°ximo de compra (*Max Bid*) y el precio m√≠nimo de venta (*Min Ask*) disponibles entre todos los *venues*.\n",
    "2.  **C√°lculo del Spread:** Definimos el beneficio potencial bruto por acci√≥n como `Spread = Max_Bid - Min_Ask`. Un spread positivo indica una oportunidad de arbitraje.\n",
    "3.  **Detecci√≥n de Flancos (*Rising Edge*):** Para evitar contar la misma oportunidad m√∫ltiples veces mientras persiste, aplicamos un filtro de \"flanco de subida\". Solo generamos una se√±al de entrada en el instante exacto en que la condici√≥n de arbitraje pasa de `False` a `True`.\n",
    "4.  **C√°lculo de Beneficio Te√≥rico:** Estimamos el P&L (Ganancia y P√©rdida) asumiendo ejecuci√≥n inmediata (Latencia 0) y tomando el volumen m√≠nimo disponible entre la orden de compra y la de venta (`min(Qty_Bid, Qty_Ask)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0f0e81",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando oportunidades de arbitraje...\n",
      "\n",
      "‚úÖ ¬°AN√ÅLISIS TERMINADO!\n",
      "Oportunidades encontradas: 25\n",
      "Beneficio Total Te√≥rico (Latencia 0): 23.45 ‚Ç¨\n",
      "\n",
      "Ejemplo de operaciones detectadas:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_26620\\4587744.py:40: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  tape['entry_signal'] = tape['is_arbitrage'] & (~tape['is_arbitrage'].shift(1).fillna(False))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_bid_venue</th>\n",
       "      <th>best_ask_venue</th>\n",
       "      <th>spread</th>\n",
       "      <th>qty_tradeable</th>\n",
       "      <th>profit_theoretical</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1762502420565157</th>\n",
       "      <td>CBOE</td>\n",
       "      <td>BME</td>\n",
       "      <td>0.010</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762503744628844</th>\n",
       "      <td>BME</td>\n",
       "      <td>CBOE</td>\n",
       "      <td>0.005</td>\n",
       "      <td>315.0</td>\n",
       "      <td>1.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762504398062141</th>\n",
       "      <td>CBOE</td>\n",
       "      <td>BME</td>\n",
       "      <td>0.005</td>\n",
       "      <td>315.0</td>\n",
       "      <td>1.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762504470336957</th>\n",
       "      <td>BME</td>\n",
       "      <td>CBOE</td>\n",
       "      <td>0.005</td>\n",
       "      <td>315.0</td>\n",
       "      <td>1.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762504517631351</th>\n",
       "      <td>BME</td>\n",
       "      <td>CBOE</td>\n",
       "      <td>0.005</td>\n",
       "      <td>315.0</td>\n",
       "      <td>1.575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 best_bid_venue best_ask_venue  spread  qty_tradeable  \\\n",
       "epoch                                                                   \n",
       "1762502420565157           CBOE            BME   0.010            5.0   \n",
       "1762503744628844            BME           CBOE   0.005          315.0   \n",
       "1762504398062141           CBOE            BME   0.005          315.0   \n",
       "1762504470336957            BME           CBOE   0.005          315.0   \n",
       "1762504517631351            BME           CBOE   0.005          315.0   \n",
       "\n",
       "                  profit_theoretical  \n",
       "epoch                                 \n",
       "1762502420565157               0.050  \n",
       "1762503744628844               1.575  \n",
       "1762504398062141               1.575  \n",
       "1762504470336957               1.575  \n",
       "1762504517631351               1.575  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_best_prices_and_volumes(tape):\n",
    "    # Creamos dos listas con los nombres de las columnas\n",
    "    bid_cols = [c for c in tape.columns if 'px_bid_0' in c]\n",
    "    ask_cols = [c for c in tape.columns if 'px_ask_0' in c]\n",
    "    \n",
    "    # Calculamos Max Bid y Min Ask, fila a fila\n",
    "    tape['best_bid_price'] = tape[bid_cols].max(axis=1)\n",
    "    tape['best_ask_price'] = tape[ask_cols].min(axis=1)\n",
    "    \n",
    "    # Identificamos qu√© mercado tiene ese precio (ej: 'BME_px_bid_0')\n",
    "    tape['best_bid_col'] = tape[bid_cols].idxmax(axis=1)\n",
    "    tape['best_ask_col'] = tape[ask_cols].idxmin(axis=1)\n",
    "    \n",
    "    # Extraer el nombre limpio del venue (en lugar de darnos 'BME_px_bid_0', nos da 'BME')\n",
    "    tape['best_bid_venue'] = tape['best_bid_col'].str.split('_').str[0]\n",
    "    tape['best_ask_venue'] = tape['best_ask_col'].str.split('_').str[0]\n",
    "    \n",
    "    return tape\n",
    "\n",
    "def find_arbitrage_opportunities(tape):\n",
    "    # Enriquecer con mejores precios\n",
    "    tape = get_best_prices_and_volumes(tape)\n",
    "    \n",
    "    # Calcular Spread\n",
    "    tape['spread'] = tape['best_bid_price'] - tape['best_ask_price']\n",
    "    \n",
    "    # Si el spread es positivo se muestra como una oportunidad de arbitraje\n",
    "    tape['is_arbitrage'] = tape['spread'] > 0\n",
    "    \n",
    "    # En esta linea marcamos que entramos si la oportunidad de arbitraje ahora es TRUE y antes era FALSE\n",
    "    tape['entry_signal'] = tape['is_arbitrage'] & (~tape['is_arbitrage'].shift(1).fillna(False))\n",
    "    \n",
    "    # Filtrar solo los momentos de entrada\n",
    "    opportunities = tape[tape['entry_signal']].copy()\n",
    "    \n",
    "    if opportunities.empty:\n",
    "        return opportunities\n",
    "\n",
    "    # C√°lculo del Beneficio Te√≥rico en Latencia 0\n",
    "    \n",
    "    # Preparamos el nombre de la columna de volumen. Si el mejor precio estaba en BME_px_bid_0, sabemos que el volumen estar√° en BME_qty_bid_0\n",
    "    opportunities['bid_qty_col'] = opportunities['best_bid_col'].str.replace('px', 'qty')\n",
    "    opportunities['ask_qty_col'] = opportunities['best_ask_col'].str.replace('px', 'qty')\n",
    "    \n",
    "    # --- EXTRACCI√ìN SEGURA DE VOL√öMENES (Correcci√≥n del error) ---\n",
    "    # Usamos listas por comprensi√≥n, que es m√°s seguro que apply en este contexto\n",
    "    qty_bids = []\n",
    "    qty_asks = []\n",
    "    \n",
    "    # Iteramos fila por fila sobre las oportunidades\n",
    "    for idx, row in opportunities.iterrows():\n",
    "        # Coge el nombre de la fila row\n",
    "        qty_bids.append(row[row['bid_qty_col']])\n",
    "        qty_asks.append(row[row['ask_qty_col']])\n",
    "    \n",
    "    opportunities['qty_bid'] = qty_bids\n",
    "    opportunities['qty_ask'] = qty_asks\n",
    "    # -------------------------------------------------------------\n",
    "    \n",
    "    # Cantidad ejecutable es el m√≠nimo de las dos puntas. Compro el valor menor que est√© en vente\n",
    "    opportunities['qty_tradeable'] = opportunities[['qty_bid', 'qty_ask']].min(axis=1)\n",
    "    \n",
    "    # Beneficio = Spread * Cantidad\n",
    "    opportunities['profit_theoretical'] = opportunities['spread'] * opportunities['qty_tradeable']\n",
    "    \n",
    "    return opportunities\n",
    "\n",
    "# --- EJECUCI√ìN ---\n",
    "try:\n",
    "    print(\"Buscando oportunidades de arbitraje...\")\n",
    "    opps = find_arbitrage_opportunities(consolidated_tape)\n",
    "    \n",
    "    print(f\"\\n‚úÖ ¬°AN√ÅLISIS TERMINADO!\")\n",
    "    print(f\"Oportunidades encontradas: {len(opps)}\")\n",
    "    \n",
    "    if not opps.empty:\n",
    "        total_theo = opps['profit_theoretical'].sum()\n",
    "        print(f\"Beneficio Total Te√≥rico (Latencia 0): {total_theo:.2f} ‚Ç¨\")\n",
    "        print(\"\\nEjemplo de operaciones detectadas:\")\n",
    "        cols_show = ['best_bid_venue', 'best_ask_venue', 'spread', 'qty_tradeable', 'profit_theoretical']\n",
    "        display(opps[cols_show].head())\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No se encontraron oportunidades. El mercado parece eficiente.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error en detecci√≥n: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
